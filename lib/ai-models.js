/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ğŸ¤– MKN Group - Merkezi AI Model KonfigÃ¼rasyonu
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 *
 * Bu dosya tÃ¼m AI modellerinin merkezi yÃ¶netimini saÄŸlar.
 * TÃ¼m admin sayfalarÄ± bu dosyadan model bilgilerini almalÄ±dÄ±r.
 *
 * Desteklenen AI SaÄŸlayÄ±cÄ±larÄ±:
 * 1. Anthropic Claude (claude-haiku, claude-sonnet, claude-opus)
 * 2. Google Gemini (gemini-2.5-flash, gemini-3-pro, gemini-3-pro-image)
 * 3. OpenAI ChatGPT (gpt-4o, gpt-4o-mini, gpt-4-turbo, o1-preview, o1-mini)
 *
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */

import { Brain, Zap, Cpu, Sparkles } from "lucide-react";

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ANTHROPIC CLAUDE MODELLERÄ°
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Claude Model API ID'leri
 * API Ã§aÄŸrÄ±larÄ±nda kullanÄ±lacak gerÃ§ek model isimleri
 */
export const CLAUDE_API_IDS = {
  haiku: "claude-haiku-4-5-20251001",
  sonnet: "claude-sonnet-4-5-20250929",
  opus: "claude-opus-4-1-20250805",
};

/**
 * Claude Model DetaylarÄ± (UI ve iÅŸlevsellik iÃ§in)
 */
export const CLAUDE_MODELS = {
  "claude-haiku": {
    id: "claude-haiku",
    value: "claude-haiku",
    name: "Claude Haiku 4.5",
    label: "Claude Haiku 4.5",
    shortLabel: "Haiku 4 (HÄ±zlÄ±)",
    provider: "Anthropic",
    apiId: CLAUDE_API_IDS.haiku,
    alias: "claude-haiku-4-5",
    description: "En hÄ±zlÄ± model, yakÄ±n-sÄ±nÄ±r zeka ile optimal performans",
    shortDescription: "HÄ±zlÄ± ve ekonomik - Temel Ã¼retim iÃ§in ideal",
    icon: Zap,
    iconEmoji: "âš¡",
    color: "from-green-500 to-emerald-600",
    bgColor: "bg-gradient-to-r from-green-500 to-emerald-600",
    maxTokens: 3000,
    defaultMaxTokens: 3000,
    versions: ["4.5"],
    capabilities: ["HÄ±zlÄ± Ãœretim", "Blog YazÄ±sÄ±", "Ä°Ã§erik Optimizasyonu", "SEO"],
    recommended: true,
    isDefault: true,
    speed: "Ã‡ok HÄ±zlÄ±",
    cost: "DÃ¼ÅŸÃ¼k",
    type: "text",
    supportsVision: false,
    supportsTools: true,
  },
  "claude-sonnet": {
    id: "claude-sonnet",
    value: "claude-sonnet",
    name: "Claude Sonnet 4.5",
    label: "Claude Sonnet 4.5",
    shortLabel: "Sonnet 4 (Ã–nerilen)",
    provider: "Anthropic",
    apiId: CLAUDE_API_IDS.sonnet,
    alias: "claude-sonnet-4-5",
    description: "En akÄ±llÄ± model, karmaÅŸÄ±k gÃ¶revler ve kodlama iÃ§in ideal",
    shortDescription: "Dengeli performans - Profesyonel geliÅŸtirme iÃ§in Ã¶nerilir",
    icon: Brain,
    iconEmoji: "ğŸ§ ",
    color: "from-purple-500 to-indigo-600",
    bgColor: "bg-gradient-to-r from-purple-500 to-indigo-600",
    maxTokens: 4000,
    defaultMaxTokens: 4000,
    versions: ["4.5"],
    capabilities: ["KarmaÅŸÄ±k Analiz", "YaratÄ±cÄ± YazÄ±m", "Teknik Ä°Ã§erik", "SEO Optimizasyonu"],
    recommended: true,
    isDefault: false,
    speed: "HÄ±zlÄ±",
    cost: "Orta",
    type: "text",
    supportsVision: true,
    supportsTools: true,
  },
  "claude-opus": {
    id: "claude-opus",
    value: "claude-opus",
    name: "Claude Opus 4.1",
    label: "Claude Opus 4.1",
    shortLabel: "Opus 4 (GÃ¼Ã§lÃ¼)",
    provider: "Anthropic",
    apiId: CLAUDE_API_IDS.opus,
    alias: "claude-opus-4-1",
    description: "Ã–zel gÃ¶revler iÃ§in istisnai model, detaylÄ± analiz",
    shortDescription: "En gÃ¼Ã§lÃ¼ model - Kompleks ve Ã¶zel iÅŸler iÃ§in en iyi seÃ§im",
    icon: Cpu,
    iconEmoji: "ğŸš€",
    color: "from-blue-500 to-cyan-600",
    bgColor: "bg-gradient-to-r from-blue-500 to-cyan-600",
    maxTokens: 3500,
    defaultMaxTokens: 3500,
    versions: ["4.1"],
    capabilities: ["DetaylÄ± Analiz", "AraÅŸtÄ±rma", "Profesyonel Ä°Ã§erik"],
    recommended: false,
    isDefault: false,
    speed: "Orta",
    cost: "YÃ¼ksek",
    type: "text",
    supportsVision: true,
    supportsTools: true,
  },
};

/**
 * Claude modelleri array formatÄ±nda (Select/Dropdown iÃ§in)
 */
export const CLAUDE_MODELS_ARRAY = Object.values(CLAUDE_MODELS);

/**
 * Claude modelleri basit array formatÄ±nda (value/label)
 */
export const CLAUDE_MODELS_SIMPLE = [
  { value: "claude-sonnet-4", label: "Sonnet 4 (Ã–nerilen)", apiId: CLAUDE_API_IDS.sonnet },
  { value: "claude-opus-4", label: "Opus 4 (GÃ¼Ã§lÃ¼)", apiId: CLAUDE_API_IDS.opus },
  { value: "claude-haiku-4", label: "Haiku 4 (HÄ±zlÄ±)", apiId: CLAUDE_API_IDS.haiku },
];

/**
 * @deprecated CLAUDE_CONTENT_STUDIO_MODELS artÄ±k kullanÄ±lmÄ±yor!
 * 
 * YENÄ° YAPI: Modeller Firestore ai_models koleksiyonundan useUnifiedAI hook'u ile Ã§ekiliyor.
 * Bu export sadece geriye dÃ¶nÃ¼k uyumluluk iÃ§in korunuyor.
 * 
 * KULLANIM:
 * ```javascript
 * import { useUnifiedAI, AI_CONTEXTS } from '@/hooks/use-unified-ai';
 * const { availableModels, selectedModel } = useUnifiedAI(AI_CONTEXTS.CONTENT_STUDIO_GENERATION);
 * ```
 * 
 * TÃœM AI ADMIN SAYFALARI GEÃ‡Ä°Å TAMAMLANINCA KALDIRILACAK.
 */
export const CLAUDE_CONTENT_STUDIO_MODELS = [
  {
    value: "claude-sonnet-4",
    label: "Claude Sonnet 4 (Ã–nerilen)",
    icon: Sparkles,
    color: "from-purple-500 to-purple-600",
    apiId: CLAUDE_API_IDS.sonnet,
  },
  {
    value: "claude-opus-4",
    label: "Claude Opus 4 (GÃ¼Ã§lÃ¼)",
    icon: Zap,
    color: "from-orange-500 to-red-500",
    apiId: CLAUDE_API_IDS.opus,
  },
  {
    value: "claude-haiku-4",
    label: "Claude Haiku 4 (HÄ±zlÄ±)",
    icon: Zap,
    color: "from-blue-500 to-cyan-500",
    apiId: CLAUDE_API_IDS.haiku,
  },
];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// GOOGLE GEMÄ°NÄ° MODELLERÄ°
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Gemini Model API ID'leri
 */
export const GEMINI_API_IDS = {
  pro3: "gemini-3-pro-preview",
  proImage3: "gemini-3-pro-image-preview",
  flash25: "gemini-2.5-flash",
};

/**
 * Gemini Chat Modelleri (DetaylÄ±)
 */
export const GEMINI_MODELS = {
  "gemini-3-pro-preview": {
    id: "gemini-3-pro-preview",
    value: "gemini-3-pro-preview",
    name: "Gemini 3 Pro",
    label: "Gemini 3 Pro",
    provider: "Google",
    apiId: GEMINI_API_IDS.pro3,
    description: "En gÃ¼Ã§lÃ¼ reasoning-first + multimodal model (1M token context)",
    icon: "ğŸš€",
    type: "text",
    features: ["Text", "Vision", "Audio", "PDF", "ğŸ› ï¸ Tools", "ğŸ§  Deep Reasoning", "ğŸ“š 1M Context"],
    supportsGrounding: false,
    supportsTools: true,
    supportsImageGen: false,
    supportsReasoning: true,
    supportsLongContext: true,
    supportedModalities: ["text", "image", "audio", "video", "pdf"],
    defaultWebSearch: false,
    maxInputTokens: 1000000,
    maxOutputTokens: 32768,
    defaultConfig: {
      temperature: 0.7,
      topP: 0.9,
      topK: 40,
      candidateCount: 1,
    },
    useCases: [
      "Complex reasoning & analysis",
      "Long document analysis",
      "Code analysis & generation",
      "Multi-step planning",
      "Agent-like automation",
      "Data analysis & reports",
    ],
  },
  "gemini-3-pro-image-preview": {
    id: "gemini-3-pro-image-preview",
    value: "gemini-3-pro-image-preview",
    name: "Gemini 3 Pro Image (Nano Banana Pro)",
    label: "Gemini 3 Pro Image",
    provider: "Google",
    apiId: GEMINI_API_IDS.proImage3,
    description: "GeliÅŸmiÅŸ gÃ¶rsel Ã¼retimi + multi-turn editing + reasoning",
    icon: "ğŸ¨",
    type: "image",
    features: ["ğŸ¨ 4K Image Gen", "âœï¸ Multi-turn Edit", "ğŸ” Google Search Grounding", "ğŸ§  Reasoning", "ğŸ“ 10 Aspect Ratios", "ğŸ–¼ï¸ 14 Input Images"],
    supportsGrounding: true,
    supportsTools: false,
    supportsImageGen: true,
    supportsMultiTurnEdit: true,
    defaultWebSearch: false,
    maxInputTokens: 65536,
    maxOutputTokens: 32768,
    maxInputImages: 14,
    maxImageSize: 7 * 1024 * 1024,
    maxTotalInputSize: 500 * 1024 * 1024,
    supportedMimeTypes: ["image/png", "image/jpeg", "image/webp", "image/heic", "image/heif"],
    supportedAspectRatios: ["1:1", "3:2", "2:3", "3:4", "4:3", "4:5", "5:4", "9:16", "16:9", "21:9"],
    supportedImageSizes: ["1K", "2K", "4K"],
    hasSynthIDWatermark: true,
    defaultConfig: {
      temperature: 1.0,
      topP: 0.95,
      topK: 64,
      candidateCount: 1,
      responseModalities: ["IMAGE", "TEXT"],
    },
  },
  "gemini-2.5-flash": {
    id: "gemini-2.5-flash",
    value: "gemini-2.5-flash",
    name: "Gemini 2.5 Flash",
    label: "Gemini 2.5 Flash",
    provider: "Google",
    apiId: GEMINI_API_IDS.flash25,
    description: "HÄ±zlÄ± + dÃ¼ÅŸÃ¼k gecikme + thinking Ã¶zelliÄŸi + web search",
    icon: "âš¡",
    type: "text",
    features: ["Text", "Vision", "Audio", "ğŸŒ Grounding (ON)", "ğŸ› ï¸ Tools", "ğŸ’­ Thinking", "âš¡ Low Latency"],
    supportsGrounding: true,
    supportsTools: true,
    supportsImageGen: false,
    supportsThinking: true,
    supportsMultimodal: true,
    supportedModalities: ["text", "image", "audio", "document"],
    defaultWebSearch: true,
    maxInputTokens: 1000000,
    maxOutputTokens: 8192,
    isDefault: true,
    performanceProfile: {
      latency: "low",
      throughput: "high",
      costEfficiency: "high",
    },
    defaultConfig: {
      temperature: 0.7,
      topP: 0.95,
      topK: 64,
      candidateCount: 1,
    },
    useCases: [
      "Real-time chatbots",
      "Customer service",
      "High-volume requests",
      "Fast content generation",
      "Automation workflows",
      "Quick analysis",
    ],
  },
};

/**
 * Gemini modelleri array formatÄ±nda
 */
export const GEMINI_MODELS_ARRAY = Object.values(GEMINI_MODELS);

/**
 * Gemini Chat iÃ§in varsayÄ±lan model
 */
export const DEFAULT_GEMINI_CHAT_MODEL = "gemini-2.5-flash";

/**
 * Gemini gÃ¶rsel Ã¼retim modeli
 */
export const GEMINI_IMAGE_MODEL = "gemini-3-pro-image-preview";

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// OPENAI CHATGPT MODELLERÄ°
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * ChatGPT Model API ID'leri
 */
export const CHATGPT_API_IDS = {
  gpt4o: "gpt-4o",
  gpt4oMini: "gpt-4o-mini",
  gpt4Turbo: "gpt-4-turbo",
  o1Preview: "o1-preview",
  o1Mini: "o1-mini",
  gpt35Turbo: "gpt-3.5-turbo",
};

/**
 * ChatGPT Modelleri (DetaylÄ±)
 */
export const CHATGPT_MODELS = {
  "gpt-4o": {
    id: "gpt-4o",
    value: "gpt-4o",
    name: "GPT-4o",
    label: "GPT-4o",
    provider: "OpenAI",
    apiId: CHATGPT_API_IDS.gpt4o,
    description: "En gÃ¼Ã§lÃ¼ ve en hÄ±zlÄ± multimodal model (128K context)",
    icon: "ğŸš€",
    type: "text",
    features: ["Text", "Vision", "ğŸ› ï¸ Tools", "ğŸ“‹ JSON Mode", "ğŸ¯ Function Calling", "ğŸ“š 128K Context"],
    supportsVision: true,
    supportsTools: true,
    supportsJSON: true,
    maxInputTokens: 128000,
    maxOutputTokens: 16384,
    defaultConfig: {
      temperature: 0.7,
      topP: 1,
      frequencyPenalty: 0,
      presencePenalty: 0,
    },
  },
  "gpt-4o-mini": {
    id: "gpt-4o-mini",
    value: "gpt-4o-mini",
    name: "GPT-4o Mini",
    label: "GPT-4o Mini",
    provider: "OpenAI",
    apiId: CHATGPT_API_IDS.gpt4oMini,
    description: "HÄ±zlÄ± ve ekonomik multimodal model",
    icon: "âš¡",
    type: "text",
    features: ["Text", "Vision", "ğŸ› ï¸ Tools", "ğŸ“‹ JSON Mode", "ğŸ’° Ekonomik", "ğŸ“š 128K Context"],
    supportsVision: true,
    supportsTools: true,
    supportsJSON: true,
    maxInputTokens: 128000,
    maxOutputTokens: 16384,
    isDefault: true,
    defaultConfig: {
      temperature: 0.7,
      topP: 1,
      frequencyPenalty: 0,
      presencePenalty: 0,
    },
  },
  "gpt-4-turbo": {
    id: "gpt-4-turbo",
    value: "gpt-4-turbo",
    name: "GPT-4 Turbo",
    label: "GPT-4 Turbo",
    provider: "OpenAI",
    apiId: CHATGPT_API_IDS.gpt4Turbo,
    description: "GÃ¼Ã§lÃ¼ ve gÃ¼venilir model (vision destekli)",
    icon: "ğŸ”¥",
    type: "text",
    features: ["Text", "Vision", "ğŸ› ï¸ Tools", "ğŸ“‹ JSON Mode", "ğŸ“š 128K Context"],
    supportsVision: true,
    supportsTools: true,
    supportsJSON: true,
    maxInputTokens: 128000,
    maxOutputTokens: 4096,
    defaultConfig: {
      temperature: 0.7,
      topP: 1,
      frequencyPenalty: 0,
      presencePenalty: 0,
    },
  },
  "o1-preview": {
    id: "o1-preview",
    value: "o1-preview",
    name: "o1 Preview",
    label: "o1 Preview",
    provider: "OpenAI",
    apiId: CHATGPT_API_IDS.o1Preview,
    description: "Ä°leri dÃ¼zey reasoning ve problem Ã§Ã¶zme",
    icon: "ğŸ§ ",
    type: "reasoning",
    features: ["ğŸ§  Advanced Reasoning", "Vision", "ğŸ” Deep Analysis", "ğŸ“ Math & Code", "ğŸ“š 128K Context"],
    supportsVision: true,
    supportsTools: false,
    supportsJSON: false,
    maxInputTokens: 128000,
    maxOutputTokens: 32768,
    defaultConfig: {
      temperature: 1,
    },
  },
  "o1-mini": {
    id: "o1-mini",
    value: "o1-mini",
    name: "o1 Mini",
    label: "o1 Mini",
    provider: "OpenAI",
    apiId: CHATGPT_API_IDS.o1Mini,
    description: "HÄ±zlÄ± reasoning modeli",
    icon: "ğŸ’¡",
    type: "reasoning",
    features: ["ğŸ§  Reasoning", "Vision", "ğŸ’° Ekonomik", "ğŸ“ Math & Code", "ğŸ“š 128K Context"],
    supportsVision: true,
    supportsTools: false,
    supportsJSON: false,
    maxInputTokens: 128000,
    maxOutputTokens: 65536,
    defaultConfig: {
      temperature: 1,
    },
  },
  "gpt-3.5-turbo": {
    id: "gpt-3.5-turbo",
    value: "gpt-3.5-turbo",
    name: "GPT-3.5 Turbo",
    label: "GPT-3.5 Turbo",
    provider: "OpenAI",
    apiId: CHATGPT_API_IDS.gpt35Turbo,
    description: "HÄ±zlÄ± ve ekonomik model",
    icon: "ğŸ’š",
    type: "text",
    features: ["Text", "ğŸ› ï¸ Tools", "ğŸ“‹ JSON Mode", "ğŸ’° En Ekonomik", "ğŸ“š 16K Context"],
    supportsVision: false,
    supportsTools: true,
    supportsJSON: true,
    maxInputTokens: 16385,
    maxOutputTokens: 4096,
    defaultConfig: {
      temperature: 0.7,
      topP: 1,
      frequencyPenalty: 0,
      presencePenalty: 0,
    },
  },
};

/**
 * ChatGPT modelleri array formatÄ±nda
 */
export const CHATGPT_MODELS_ARRAY = Object.values(CHATGPT_MODELS);

/**
 * ChatGPT varsayÄ±lan model
 */
export const DEFAULT_CHATGPT_MODEL = "gpt-4o-mini";

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// VARSAYILAN MODELLER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * TÃ¼m saÄŸlayÄ±cÄ±lar iÃ§in varsayÄ±lan modeller
 */
export const DEFAULT_MODELS = {
  claude: "claude-haiku",
  gemini: DEFAULT_GEMINI_CHAT_MODEL,
  chatgpt: DEFAULT_CHATGPT_MODEL,
};

/**
 * Claude iÃ§in varsayÄ±lan model
 */
export const DEFAULT_CLAUDE_MODEL = "claude-haiku";

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// YARDIMCI FONKSÄ°YONLAR
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Model ID'den API ID'yi al
 * @param {string} modelId - Model ID (Ã¶rn: "claude-haiku", "claude-sonnet-4")
 * @param {string} provider - SaÄŸlayÄ±cÄ± ("claude" | "gemini" | "chatgpt")
 * @returns {string} API ID
 */
export function getApiIdFromModelId(modelId, provider = "claude") {
  if (provider === "claude") {
    // KÄ±sa format kontrolÃ¼ (claude-haiku, claude-sonnet, claude-opus)
    if (CLAUDE_MODELS[modelId]) {
      return CLAUDE_MODELS[modelId].apiId;
    }
    // Uzun format kontrolÃ¼ (claude-sonnet-4, claude-opus-4, claude-haiku-4)
    const shortId = modelId.replace(/-4$/, "").replace("claude-", "claude-");
    if (modelId.includes("sonnet")) return CLAUDE_API_IDS.sonnet;
    if (modelId.includes("opus")) return CLAUDE_API_IDS.opus;
    if (modelId.includes("haiku")) return CLAUDE_API_IDS.haiku;
  }
  
  if (provider === "gemini") {
    if (GEMINI_MODELS[modelId]) {
      return GEMINI_MODELS[modelId].apiId;
    }
  }
  
  if (provider === "chatgpt") {
    if (CHATGPT_MODELS[modelId]) {
      return CHATGPT_MODELS[modelId].apiId;
    }
  }
  
  return modelId; // Bulunamazsa orijinal ID'yi dÃ¶ndÃ¼r
}

/**
 * Model bilgilerini al
 * @param {string} modelId - Model ID
 * @param {string} provider - SaÄŸlayÄ±cÄ±
 * @returns {Object|null} Model bilgileri
 */
export function getModelInfo(modelId, provider = "claude") {
  if (provider === "claude") {
    if (CLAUDE_MODELS[modelId]) return CLAUDE_MODELS[modelId];
    // Uzun format kontrolÃ¼
    if (modelId.includes("sonnet")) return CLAUDE_MODELS["claude-sonnet"];
    if (modelId.includes("opus")) return CLAUDE_MODELS["claude-opus"];
    if (modelId.includes("haiku")) return CLAUDE_MODELS["claude-haiku"];
  }
  
  if (provider === "gemini") {
    return GEMINI_MODELS[modelId] || null;
  }
  
  if (provider === "chatgpt") {
    return CHATGPT_MODELS[modelId] || null;
  }
  
  return null;
}

/**
 * Model adÄ±nÄ± al (UI gÃ¶sterimi iÃ§in)
 * @param {string} modelId - Model ID
 * @param {string} provider - SaÄŸlayÄ±cÄ±
 * @returns {string} Model adÄ±
 */
export function getModelName(modelId, provider = "claude") {
  const info = getModelInfo(modelId, provider);
  return info?.name || info?.label || modelId;
}

/**
 * Model ikonunu al
 * @param {string} modelId - Model ID
 * @param {string} provider - SaÄŸlayÄ±cÄ±
 * @returns {string|Component} Ä°kon
 */
export function getModelIcon(modelId, provider = "claude") {
  const info = getModelInfo(modelId, provider);
  return info?.icon || info?.iconEmoji || "ğŸ¤–";
}

/**
 * VarsayÄ±lan Claude model ID'sini API ID'ye Ã§evir
 * @param {string} modelId - KÄ±sa model ID
 * @returns {string} API ID
 */
export function claudeModelToApiId(modelId) {
  return getApiIdFromModelId(modelId, "claude");
}

/**
 * Model seÃ§imi iÃ§in standart dropdown seÃ§enekleri oluÅŸtur
 * @param {string} provider - SaÄŸlayÄ±cÄ± ("claude" | "gemini" | "chatgpt")
 * @param {string} format - Format ("simple" | "detailed")
 * @returns {Array} Dropdown seÃ§enekleri
 */
export function getModelOptions(provider = "claude", format = "simple") {
  if (provider === "claude") {
    if (format === "simple") {
      return CLAUDE_MODELS_SIMPLE;
    }
    return CLAUDE_MODELS_ARRAY;
  }
  
  if (provider === "gemini") {
    return GEMINI_MODELS_ARRAY;
  }
  
  if (provider === "chatgpt") {
    return CHATGPT_MODELS_ARRAY;
  }
  
  return [];
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// AI Ä°Ã‡ERÄ°K AYARLARI
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * AI Ä°Ã§erik Ã¼retim ayarlarÄ±
 */
export const AI_CONTENT_SETTINGS = {
  creativity: {
    label: "YaratÄ±cÄ±lÄ±k Seviyesi",
    description: "Ä°Ã§eriÄŸin ne kadar yaratÄ±cÄ± ve Ã¶zgÃ¼n olacaÄŸÄ±nÄ± belirler",
    min: 0,
    max: 100,
    step: 10,
    default: 70,
  },
  technicality: {
    label: "Teknik Detay Seviyesi",
    description: "Ä°Ã§eriÄŸe dahil edilecek teknik bilgi miktarÄ±",
    min: 0,
    max: 100,
    step: 10,
    default: 60,
  },
  seoOptimization: {
    label: "SEO Optimizasyonu",
    description: "Anahtar kelime yoÄŸunluÄŸu ve SEO odaÄŸÄ±",
    min: 0,
    max: 100,
    step: 10,
    default: 80,
  },
  readability: {
    label: "Okunabilirlik",
    description: "Metnin anlaÅŸÄ±labilirlik seviyesi",
    min: 0,
    max: 100,
    step: 10,
    default: 75,
  },
};

/**
 * VarsayÄ±lan AI ayarlarÄ±
 */
export const DEFAULT_AI_SETTINGS = {
  creativity: AI_CONTENT_SETTINGS.creativity.default,
  technicality: AI_CONTENT_SETTINGS.technicality.default,
  seoOptimization: AI_CONTENT_SETTINGS.seoOptimization.default,
  readability: AI_CONTENT_SETTINGS.readability.default,
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// TÃœM MODELLERÄ° TEK BÄ°R YERDEN EXPORT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * TÃ¼m AI modelleri (tÃ¼m saÄŸlayÄ±cÄ±lar)
 */
export const ALL_AI_MODELS = {
  claude: CLAUDE_MODELS,
  gemini: GEMINI_MODELS,
  chatgpt: CHATGPT_MODELS,
};

/**
 * TÃ¼m AI modelleri array formatÄ±nda
 */
export const ALL_AI_MODELS_ARRAY = [
  ...CLAUDE_MODELS_ARRAY.map((m) => ({ ...m, provider: "claude" })),
  ...GEMINI_MODELS_ARRAY.map((m) => ({ ...m, provider: "gemini" })),
  ...CHATGPT_MODELS_ARRAY.map((m) => ({ ...m, provider: "chatgpt" })),
];

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ”„ DÄ°NAMÄ°K FIRESTORE ENTEGRASYONu
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

/**
 * Bu bÃ¶lÃ¼m Firestore'dan dinamik AI ayarlarÄ± Ã§ekme iÅŸlemi iÃ§in kullanÄ±lÄ±r.
 * Admin panelinden AI ayarlarÄ± deÄŸiÅŸtirildiÄŸinde, bu fonksiyonlar
 * gÃ¼ncel deÄŸerleri Ã§ekmek iÃ§in kullanÄ±labilir.
 * 
 * KullanÄ±m:
 * - Server-side: import { getDynamicAiSettings } from '@/lib/ai-models'
 * - Client-side: use useUnifiedAI hook from '@/hooks/use-unified-ai'
 */

// Cache for dynamic settings
let dynamicSettingsCache = null;
let cacheTimestamp = null;
const CACHE_DURATION = 5 * 60 * 1000; // 5 minutes

/**
 * Get dynamic AI settings from Firestore
 * Falls back to static values if Firestore is unavailable
 * 
 * @param {boolean} forceRefresh - Force refresh from Firestore
 * @returns {Promise<object>} AI settings object
 */
export async function getDynamicAiSettings(forceRefresh = false) {
  // Check cache
  const now = Date.now();
  if (!forceRefresh && dynamicSettingsCache && cacheTimestamp && (now - cacheTimestamp < CACHE_DURATION)) {
    return dynamicSettingsCache;
  }

  try {
    // Dynamic import to avoid circular dependencies
    const { getCachedModels, getCachedPrompts } = await import("@/lib/services/ai-settings-service");
    
    const [models, prompts] = await Promise.all([
      getCachedModels(),
      getCachedPrompts(),
    ]);

    if (models && models.length > 0) {
      // Build settings from Firestore data
      const settings = {
        claudeApiIds: {},
        geminiApiIds: {},
        openaiApiIds: {},
        models: {},
        prompts: {},
      };

      models.forEach(model => {
        settings.models[model.modelId] = model;
        
        // Build API ID mappings
        if (model.provider === 'claude') {
          if (model.modelId.includes('haiku')) settings.claudeApiIds.haiku = model.apiId;
          if (model.modelId.includes('sonnet')) settings.claudeApiIds.sonnet = model.apiId;
          if (model.modelId.includes('opus')) settings.claudeApiIds.opus = model.apiId;
        }
        if (model.provider === 'gemini') {
          if (model.modelId.includes('flash')) settings.geminiApiIds.flash = model.apiId;
          if (model.modelId.includes('pro_3_image')) settings.geminiApiIds.image = model.apiId;
          else if (model.modelId.includes('pro_3')) settings.geminiApiIds.pro = model.apiId;
        }
        if (model.provider === 'openai') {
          if (model.modelId === 'gpt4o') settings.openaiApiIds.gpt4o = model.apiId;
          if (model.modelId === 'gpt4o_mini') settings.openaiApiIds.gpt4oMini = model.apiId;
        }
      });

      prompts.forEach(prompt => {
        settings.prompts[prompt.key] = prompt;
      });

      // Cache the result
      dynamicSettingsCache = settings;
      cacheTimestamp = now;

      return settings;
    }
  } catch (error) {
    console.warn("Could not load dynamic AI settings, using static fallback:", error.message);
  }

  // Return static fallback
  return {
    claudeApiIds: CLAUDE_API_IDS,
    geminiApiIds: GEMINI_API_IDS,
    openaiApiIds: CHATGPT_API_IDS,
    models: { ...CLAUDE_MODELS, ...GEMINI_MODELS, ...CHATGPT_MODELS },
    prompts: {},
  };
}

/**
 * Get API ID dynamically (with Firestore fallback)
 * 
 * @param {string} provider - 'claude' | 'gemini' | 'openai'
 * @param {string} modelKey - Model key like 'haiku', 'sonnet', 'flash', etc.
 * @returns {Promise<string>} API ID
 */
export async function getDynamicApiId(provider, modelKey) {
  const settings = await getDynamicAiSettings();
  
  switch (provider) {
    case 'claude':
      return settings.claudeApiIds[modelKey] || CLAUDE_API_IDS[modelKey];
    case 'gemini':
      return settings.geminiApiIds[modelKey] || GEMINI_API_IDS[modelKey];
    case 'openai':
      return settings.openaiApiIds[modelKey] || CHATGPT_API_IDS[modelKey];
    default:
      return null;
  }
}

/**
 * Get prompt content dynamically
 * 
 * @param {string} key - Prompt key
 * @returns {Promise<string|null>} Prompt content
 */
export async function getDynamicPrompt(key) {
  const settings = await getDynamicAiSettings();
  return settings.prompts[key]?.content || null;
}

/**
 * Clear dynamic settings cache
 */
export function clearDynamicSettingsCache() {
  dynamicSettingsCache = null;
  cacheTimestamp = null;
}

/**
 * Check if dynamic settings are available
 * 
 * @returns {Promise<boolean>}
 */
export async function isDynamicSettingsAvailable() {
  try {
    const { checkAiSettingsSeeded } = await import("@/lib/services/ai-settings-seed");
    return await checkAiSettingsSeeded();
  } catch {
    return false;
  }
}

